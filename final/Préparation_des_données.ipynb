{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Récupération et Préparation des données\n",
    "\n",
    "|Auteur|Centre|\n",
    "|---|---|\n",
    "|ACQUART Quentin|Aix-en-Provence|\n",
    "|DIMEGLIO Nicolas|Aix-en-Provence|\n",
    "|SIXDENIER Alexandre|Aix-en-Provence|\n",
    "|VESSERON Alexandre|Aix-en-Provence|\n",
    "|ROMANO Sébastien|Aix-en-Provence|"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import des différentes bibliothèques"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image as Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Téléchargement des données et dezippage\n",
    "\n",
    "\n",
    "1. Téléchargez les fichiers zip [Datasets Livrable 1](https://cesifr-my.sharepoint.com/personal/bcohen_cesi_fr/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Fbcohen%5Fcesi%5Ffr%2FDocuments%2FOption%20Data%20Science%2FDataset%20projet&originalPath=aHR0cHM6Ly9jZXNpZnItbXkuc2hhcmVwb2ludC5jb20vOmY6L2cvcGVyc29uYWwvYmNvaGVuX2Nlc2lfZnIvRW1na3k5Sm4xQnhHbE84TzZVMDVpYThCSEhkd2JfR0hFd1E3MVNkZTBqbjZDQT9ydGltZT1MS2hHamJ5QjJVZw)\n",
    "Veuillez déposer ces fichiers Zip dans le répertoire `../Dataset/Project_Dataset_Zip`\n",
    "<a id='section_1'></a>\n",
    "### Architecture des dossiers :\n",
    "- >../Dataset\n",
    "     - >/Project_Dataset_Zip\n",
    "\n",
    "\n",
    "2. Respectez l'architecture ci-dessus puis lancez le jupyter\n",
    "<br><br>\n",
    "<div style=\"color:red\">Attention cette action peut être longue <b>(+1h)</b></div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#Path\n",
    "dataset_dir_path = \"../Dataset\"\n",
    "zip_dataset_path = \"../Dataset/Project_Dataset_Zip\"\n",
    "extracted_dataset_path = \"../Dataset/Project_Dataset_Unzip\"\n",
    "clean_dataset_path = \"../Dataset/Project_Dataset_Clean\"\n",
    "light_dataset_path = \"../Dataset/Project_Dataset_Test\"\n",
    "dataset_size = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Extraction des dossiers Zip dans ../Dataset/Project_Dataset_Unzip\n",
    "def extract_zip(zip_path,extract_path):\n",
    "    if not os.path.exists(extract_path):\n",
    "        os.mkdir(extract_path)\n",
    "    for directory in os.listdir(zip_path):\n",
    "        print(directory)\n",
    "        with zipfile.ZipFile(zip_path + \"/\" + directory, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Première préparation des données afin de les rendre exploitables\n",
    "Nettoyage du jeu de données en ouvrant chaque image afin de la copier sans métadata dans `../Dataset/Project_Dataset_Clean`\n",
    "<br>Toute les images corrompues/invalides ne seront pas copiés et un fichier de log `Error_file.log` sera généré dans le dossier `..\\Dataset`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def clean_dataset(dataset_path,extract_path):\n",
    "    for directory in os.listdir(extract_path):\n",
    "        print(extract_path + \"/\" + directory)\n",
    "        if not os.path.exists(dataset_path):\n",
    "            os.mkdir(dataset_path)\n",
    "        if not os.path.exists(dataset_path + \"/\" + directory):\n",
    "            os.mkdir(dataset_path + \"/\" + directory)\n",
    "        for file in os.listdir(extract_path + \"/\" + directory):\n",
    "            if not os.path.exists(dataset_path + \"/\"+ directory + \"/\" + file):\n",
    "                image = None\n",
    "                try:\n",
    "                    image = Image.open(extract_path + \"/\" + directory + \"/\" + file)\n",
    "                    data = list(image.getdata())\n",
    "                    image_without_exif = Image.new(image.mode, image.size)\n",
    "                    image_without_exif.putdata(data)\n",
    "                    image_without_exif.save(clean_dataset_path + \"/\" + directory + \"/\" + file)\n",
    "                except:\n",
    "                    if file == \"desktop.ini\":\n",
    "                        os.remove(extract_path + \"/\" + directory + \"/\" + file)\n",
    "                    else:\n",
    "                        print(extract_path + \"/\" + directory + \"/\" + file)\n",
    "                        print(image)\n",
    "                        if not os.path.exists(\"../Dataset/Error_file.log\"):\n",
    "                            fp = open('../Dataset/Error_file.log','w')\n",
    "                            fp.close()\n",
    "                        fp = open('../Dataset/Error_file.log','a')\n",
    "                        fp.write('\\n'+extract_path + \"/\" + directory + \"/\" + file)\n",
    "                        fp.write('\\n'+str(image))\n",
    "                        fp.close()\n",
    "                        image.close()\n",
    "                        #os.remove(extract_path + \"/\" + directory + \"/\" + file)\n",
    "                        try:\n",
    "                            os.remove(dataset_path + \"/\" + directory + \"/\" + file)\n",
    "                        except:\n",
    "                            print(\"Failed to erase image\"+\"/\"+directory+\"/\"+file)\n",
    "                    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Set de test Intermédiaire\n",
    "Création d'un dataset plus léger, en récupérant aléatoirement des images dans le dataset\n",
    "<br> Par défaut la valeur est de 20%.\n",
    "<br> Pour changer la taille du dataset veuillez éditer la variable `dataset_size`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def dataset_test(light_dataset_path,dataset_path,dataset_size = 0.2):\n",
    "    if not os.path.exists(light_dataset_path):\n",
    "        os.mkdir(light_dataset_path)\n",
    "    for directory in os.listdir(dataset_path):\n",
    "        for file in os.listdir(dataset_path + \"/\" + directory):\n",
    "            random_number = random()\n",
    "            if not os.path.exists(light_dataset_path + \"/\" + directory):\n",
    "                os.mkdir(light_dataset_path + \"/\" + directory)\n",
    "            if random_number < dataset_size :\n",
    "                shutil.copy2(dataset_path + \"/\" + directory + \"/\" + file, light_dataset_path + \"/\" + directory)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Code pour supprimer le `light_dataset` afin de le regénérer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Uncomment to clear light_dataset\n",
    "def remove_data_set(dataset_path):\n",
    "    for directory in os.listdir(dataset_path):\n",
    "        for file in os.listdir(dataset_path + \"/\" + directory):\n",
    "            os.remove(dataset_path + \"/\" + directory + \"/\" + file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "binary_dataset_dir_path = \"../Dataset_Binary_Project\"\n",
    "dataset_to_extract_path = \"../Dataset/Project_Dataset_Clean\"\n",
    "binary_dataset_test_path = \"../Dataset_Binary_Project_test\"\n",
    "class_to_compare = \"Photo\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_binary_dataset(dataset_to_extract,binary_dataset_dir_path, class_to_compare):\n",
    "    if not os.path.exists(binary_dataset_dir_path):\n",
    "        os.mkdir(binary_dataset_dir_path)\n",
    "\n",
    "    for directory in os.listdir(dataset_to_extract):\n",
    "        print(dataset_to_extract + \"/\" + directory)\n",
    "        if directory == class_to_compare:\n",
    "            continue\n",
    "\n",
    "        print(\"Check directory \" + binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare)\n",
    "        if not os.path.exists(binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare):\n",
    "            os.mkdir(binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare)\n",
    "            print(\"Create directory \" + binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare)\n",
    "\n",
    "        print(\"Check directory \" + binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + directory)\n",
    "        if not os.path.exists(binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + directory):\n",
    "            os.mkdir(binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + directory)\n",
    "            print(\"Create directory \" + binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + directory)\n",
    "\n",
    "        print(\"Check directory \" + binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + class_to_compare)\n",
    "        if not os.path.exists(binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + class_to_compare):\n",
    "            os.mkdir(binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + class_to_compare)\n",
    "            print(\"Create directory \" + binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + class_to_compare)\n",
    "\n",
    "        print(\"Copy file in \" + binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + directory)\n",
    "        for file in os.listdir(dataset_to_extract + \"/\" + directory):\n",
    "            if not os.path.exists(binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + directory + \"/\" + file):\n",
    "                shutil.copy2(dataset_to_extract + \"/\" + directory + \"/\" + file, binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + directory)\n",
    "        print(\"Finished copy\")\n",
    "\n",
    "        print(\"Copy file in \" + binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + class_to_compare)\n",
    "        for file in os.listdir(dataset_to_extract + \"/\" + class_to_compare):\n",
    "            if not os.path.exists(binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + class_to_compare + \"/\" + file):\n",
    "                shutil.copy2(dataset_to_extract + \"/\" + class_to_compare + \"/\" + file, binary_dataset_dir_path + \"/\" + directory + \"_\" + class_to_compare + \"/\" + class_to_compare)\n",
    "        print(\"Finished copy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_binary_dataset_test(dataset_to_extract,binary_dataset_test, class_to_compare, balanced=False):\n",
    "    if not os.path.exists(binary_dataset_test):\n",
    "        os.mkdir(binary_dataset_test)\n",
    "\n",
    "    if not os.path.exists(binary_dataset_test + \"/\" + class_to_compare):\n",
    "        os.mkdir(binary_dataset_test + \"/\" + class_to_compare)\n",
    "\n",
    "    if not os.path.exists(binary_dataset_test + \"/all_pictures\"):\n",
    "        os.mkdir(binary_dataset_test + \"/all_pictures\")\n",
    "\n",
    "    nb_classes = len(os.listdir(dataset_to_extract))\n",
    "    half_dataset = len(os.listdir(dataset_to_extract+\"/\"+class_to_compare))\n",
    "    nb_files_by_directory = int(half_dataset/(nb_classes-1))\n",
    "\n",
    "    if balanced:\n",
    "        print(\"Creating Balanced dataset with \" + str(nb_files_by_directory) + \" files per class\")\n",
    "    else:\n",
    "        print(\"Creating Unbalanced dataset\")\n",
    "\n",
    "    for directory in os.listdir(dataset_to_extract):\n",
    "        print(dataset_to_extract + \"/\" + directory)\n",
    "\n",
    "        if directory == class_to_compare:\n",
    "            print(\"Skipping class : \",class_to_compare)\n",
    "            continue\n",
    "\n",
    "        if balanced :\n",
    "            compteur = 0\n",
    "            print(\"Copy file in \" + binary_dataset_test + \"/all_pictures\")\n",
    "            for file in shuffle_dataset(os.listdir(dataset_to_extract + \"/\" + directory))[:nb_files_by_directory-1]:\n",
    "                if not os.path.exists(binary_dataset_test + \"/all_pictures/\" + file):\n",
    "                    shutil.copy2(dataset_to_extract + \"/\" + directory + \"/\" + file, binary_dataset_test + \"/all_pictures\")\n",
    "                    compteur += 1\n",
    "            print(\"Finished copy of : \" + str(compteur) + \" files\")\n",
    "        else:\n",
    "            print(\"Copy file in \" + binary_dataset_test + \"/all_pictures\")\n",
    "            for file in os.listdir(dataset_to_extract + \"/\" + directory):\n",
    "                if not os.path.exists(binary_dataset_test + \"/all_pictures/\" + file):\n",
    "                    shutil.copy2(dataset_to_extract + \"/\" + directory + \"/\" + file, binary_dataset_test + \"/all_pictures\")\n",
    "                    compteur += 1\n",
    "            print(\"Finished copy of : \" + str(compteur) + \" files\")\n",
    "\n",
    "    compteur = 0\n",
    "    print(\"Copy file in \" + binary_dataset_test + \"/\" + class_to_compare)\n",
    "    for file in os.listdir(dataset_to_extract + \"/\" + class_to_compare):\n",
    "        if not os.path.exists(binary_dataset_test + \"/\" + class_to_compare + \"/\" + file):\n",
    "            shutil.copy2(dataset_to_extract + \"/\" + class_to_compare + \"/\" + file, binary_dataset_test + \"/\" + class_to_compare)\n",
    "            compteur += 1\n",
    "    print(\"Finished copy of : \" + str(compteur) + \" files\")\n",
    "\n",
    "def get_random():\n",
    "    return 0.1\n",
    "\n",
    "def shuffle_dataset(directory):\n",
    "    random.shuffle(directory, get_random)\n",
    "    return directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Livrable 1\n",
    "\n",
    "Les fonction ci-dessous nous permet de nettoyer et extraire les données du premier jeu de données pour le livrable 1."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../Dataset/Project_Dataset_Zip'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_4244/499712260.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mextract_zip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip_dataset_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mextracted_dataset_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_4244/2737516736.py\u001B[0m in \u001B[0;36mextract_zip\u001B[1;34m(zip_path, extract_path)\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mextract_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmkdir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mextract_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mdirectory\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdirectory\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mzipfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mZipFile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip_path\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"/\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mdirectory\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mzip_ref\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: '../Dataset/Project_Dataset_Zip'"
     ]
    }
   ],
   "source": [
    "extract_zip(zip_dataset_path, extracted_dataset_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean_dataset(clean_dataset_path,extracted_dataset_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Création du dataset de test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test(light_dataset_path,clean_dataset_path,dataset_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Création des datasets pour les binary classifieurs ainsi que le dataset de test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_binary_dataset(dataset_to_extract_path,binary_dataset_dir_path,class_to_compare)\n",
    "create_binary_dataset_test(dataset_to_extract_path,binary_dataset_test_path,class_to_compare, balanced=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Livrable 2\n",
    "La fonction ci-dessous nous permet de nettoyer et extraire les données du second jeu de données pour le livrable 2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extract_zip('../DatasetL2/Project_Dataset_Zip/', '../DatasetL2/Project_Dataset_Unzip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#clean_dataset('../DatasetL2/Project_Dataset_Clean','../DatasetL2/Project_Dataset_Unzip')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Groupe non officiel 1\n",
    "# Livrable 2 - Classification binaire Création du model\n",
    "\n",
    "|Auteur|Centre|\n",
    "|---|---|\n",
    "|ACQUART Quentin|Aix-en-Provence|\n",
    "|DIMEGLIO Nicolas|Aix-en-Provence|\n",
    "|ROMANO Sébastien|Aix-en-Provence|\n",
    "|SIXDENIER Alexandre|Aix-en-Provence|\n",
    "|VESSERON Alexandre|Aix-en-Provence|\n",
    "\n",
    "## Rappel du sujet\n",
    "L'entreprise voulant automatiser la sélection de photos pour l'annotations, le but est de fournir une méthode de classification binaire à fin de filtrer les images qui ne sont pas des photos du dataset de départ. Pour ce faire nous allons nous appuyer sur l'architecture des réseaux de neurones, ainsi que l'analyse des résultats obtenus.\n",
    "Toutes les parties doivent être détaillées dans le notebook :\n",
    "    - les paramètre du réseau,\n",
    "    - la fonction de perte ainsi que l'algorithme d'optimisation utilisé pour l’entraînement."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyse à effectuer\n",
    "\n",
    "Le but de cette étape va être le suivant :\n",
    "    Traiter l'ensemble des photographies via un bruitage puis un débruitage à fin d'améliorer leur qualité.\n",
    "    Le tout à l'aide d'un auto-encodeur à convolution.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import des différentes bibliothèques"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import zipfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Téléchargement des données et dezippage\n",
    "Pour cette partie se referrer au notebook [Préparation des données](Préparation_des_données.ipynb#section_1)\n",
    "## Récupération des données\n",
    "Une fois les datasets mis en place, sélectionner le dataset à utiliser dans la variable `data_dir`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean_dataset = \"../DatasetL2/Project_Dataset_Clean\"\n",
    "light_dataset = \"../DatasetL2/Project_Dataset_Test\"\n",
    "\n",
    "data_dir = clean_dataset\n",
    "\n",
    "data_dir = pathlib.Path(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Groupe non officiel 1\n",
    "# Livrable 2 - Classification binaire Création du model\n",
    "\n",
    "|Auteur|Centre|\n",
    "|---|---|\n",
    "|ACQUART Quentin|Aix-en-Provence|\n",
    "|DIMEGLIO Nicolas|Aix-en-Provence|\n",
    "|ROMANO Sébastien|Aix-en-Provence|\n",
    "|SIXDENIER Alexandre|Aix-en-Provence|\n",
    "|VESSERON Alexandre|Aix-en-Provence|\n",
    "\n",
    "## Rappel du sujet\n",
    "L'entreprise voulant automatiser la sélection de photos pour l'annotations, le but est de fournir une méthode de classification binaire à fin de filtrer les images qui ne sont pas des photos du dataset de départ. Pour ce faire nous allons nous appuyer sur l'architecture des réseaux de neurones, ainsi que l'analyse des résultats obtenus.\n",
    "Toutes les parties doivent être détaillées dans le notebook :\n",
    "    - les paramètre du réseau,\n",
    "    - la fonction de perte ainsi que l'algorithme d'optimisation utilisé pour l’entraînement."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyse à effectuer\n",
    "\n",
    "Le but de cette étape va être le suivant :\n",
    "    Traiter l'ensemble des photographies via un bruitage puis un débruitage à fin d'améliorer leur qualité.\n",
    "    Le tout à l'aide d'un auto-encodeur à convolution.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import des différentes bibliothèques"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import zipfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Téléchargement des données et dezippage\n",
    "Pour cette partie se referrer au notebook [Préparation des données](Préparation_des_données.ipynb#section_1)\n",
    "## Récupération des données\n",
    "Une fois les datasets mis en place, sélectionner le dataset à utiliser dans la variable `data_dir`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(WindowsPath('../DatasetL2/Project_Dataset_Clean'), dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12832/1495635025.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mdata_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpathlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPath\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdata_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.33\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\ecole\\a5\\projet_datascience_a5\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001B[0m in \u001B[0;36mtrain_test_split\u001B[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[0m\n\u001B[0;32m   2417\u001B[0m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"At least one array required as input\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2418\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2419\u001B[1;33m     \u001B[0marrays\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindexable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2420\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2421\u001B[0m     \u001B[0mn_samples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marrays\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\ecole\\a5\\projet_datascience_a5\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mindexable\u001B[1;34m(*iterables)\u001B[0m\n\u001B[0;32m    368\u001B[0m     \"\"\"\n\u001B[0;32m    369\u001B[0m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0m_make_indexable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mX\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterables\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 370\u001B[1;33m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    371\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    372\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\ecole\\a5\\projet_datascience_a5\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    326\u001B[0m     \"\"\"\n\u001B[0;32m    327\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 328\u001B[1;33m     \u001B[0mlengths\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mX\u001B[0m \u001B[1;32min\u001B[0m \u001B[0marrays\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mX\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    329\u001B[0m     \u001B[0muniques\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    330\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\ecole\\a5\\projet_datascience_a5\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    326\u001B[0m     \"\"\"\n\u001B[0;32m    327\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 328\u001B[1;33m     \u001B[0mlengths\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mX\u001B[0m \u001B[1;32min\u001B[0m \u001B[0marrays\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mX\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    329\u001B[0m     \u001B[0muniques\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlengths\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    330\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\ecole\\a5\\projet_datascience_a5\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m_num_samples\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    267\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    268\u001B[0m             raise TypeError(\n\u001B[1;32m--> 269\u001B[1;33m                 \u001B[1;34m\"Singleton array %r cannot be considered a valid collection.\"\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    270\u001B[0m             )\n\u001B[0;32m    271\u001B[0m         \u001B[1;31m# Check that shape is returning an integer or default to len\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Singleton array array(WindowsPath('../DatasetL2/Project_Dataset_Clean'), dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "clean_dataset = \"../DatasetL2/Project_Dataset_Clean\"\n",
    "\n",
    "data_dir = clean_dataset\n",
    "\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "X_train, _, y_train, _ = train_test_split(data_dir,data_dir, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "image_h = 180\n",
    "image_w = 180\n",
    "batch_s = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Lisser le poids des images\n",
    "\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# Add a Dense layer with a L1 activity regularizer\n",
    "encoded = layers.Dense(encoding_dim, activation='relu',\n",
    "                       activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Groupe non officiel 1\n",
    "# Livrable 2 - Traitement d'images\n",
    "\n",
    "|Auteur|Centre|\n",
    "|---|---|\n",
    "|ACQUART Quentin|Aix-en-Provence|\n",
    "|DIMEGLIO Nicolas|Aix-en-Provence|\n",
    "|ROMANO Sébastien|Aix-en-Provence|\n",
    "|SIXDENIER Alexandre|Aix-en-Provence|\n",
    "|VESSERON Alexandre|Aix-en-Provence|\n",
    "\n",
    "## Rappel du sujet\n",
    "L'entreprise voulant automatiser la sélection de photos pour l'annotations, le but est de fournir une méthode de classification binaire à fin de filtrer les images qui ne sont pas des photos du dataset de départ. Pour ce faire nous allons nous appuyer sur l'architecture des réseaux de neurones, ainsi que l'analyse des résultats obtenus.\n",
    "Toutes les parties doivent être détaillées dans le notebook :\n",
    "    - les paramètre du réseau,\n",
    "    - la fonction de perte ainsi que l'algorithme d'optimisation utilisé pour l’entraînement."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyse à effectuer\n",
    "\n",
    "Le but de cette étape va être le suivant :\n",
    "    Traiter l'ensemble des photographies via un bruitage puis un débruitage à fin d'améliorer leur qualité.\n",
    "    Le tout à l'aide d'un auto-encodeur à convolution.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import des différentes bibliothèques"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import zipfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Téléchargement des données et dezippage\n",
    "Pour cette partie se referrer au notebook [Préparation des données](Préparation_des_données.ipynb#section_1)\n",
    "## Récupération des données\n",
    "Une fois les datasets mis en place, sélectionner le dataset à utiliser dans la variable `data_dir`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "clean_dataset = \"../DatasetL2/Project_Dataset_Unzip\"\n",
    "\n",
    "data_dir = clean_dataset\n",
    "\n",
    "data_dir = pathlib.Path(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "image_h = 180\n",
    "image_w = 180\n",
    "batch_s = 32"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 files belonging to 1 classes.\n",
      "Using 120 files for training.\n",
      "Found 150 files belonging to 1 classes.\n",
      "Using 30 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Le train_set\n",
    "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split= 0.20,\n",
    "  subset = 'training',\n",
    "  seed=42,\n",
    "  image_size=(image_h, image_w),\n",
    "  batch_size=batch_s,\n",
    "  color_mode='rgb',\n",
    "  label_mode='int',\n",
    "  labels=\"inferred\"\n",
    ")\n",
    "\n",
    "# Le test_set\n",
    "test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split= 0.20,\n",
    "  subset = 'validation',\n",
    "  seed=42,\n",
    "  image_size=(image_h, image_w),\n",
    "  batch_size=batch_s,\n",
    "  color_mode='rgb',\n",
    "  label_mode='int',\n",
    "  labels=\"inferred\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "encoding_dim = 32\n",
    "\n",
    "input_img = keras.Input(shape=(784,))\n",
    "\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "input_img = keras.Input(shape=(784,))\n",
    "encoded = layers.Dense(128, activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using dataset as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5796/3311354529.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m                 \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m256\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m                 \u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m                 validation_data=(test_set,test_set))\n\u001B[0m",
      "\u001B[1;32m~\\PycharmProjects\\DataScience\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1146\u001B[0m           \u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1147\u001B[0m           \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1148\u001B[1;33m           steps_per_execution=self._steps_per_execution)\n\u001B[0m\u001B[0;32m   1149\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1150\u001B[0m       \u001B[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\DataScience\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1381\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"model\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"_cluster_coordinator\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1382\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0m_ClusterCoordinatorDataHandler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1383\u001B[1;33m   \u001B[1;32mreturn\u001B[0m \u001B[0mDataHandler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1384\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1385\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\DataScience\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1148\u001B[0m         \u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m         \u001B[0mdistribution_strategy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdistribute\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_strategy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1150\u001B[1;33m         model=model)\n\u001B[0m\u001B[0;32m   1151\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1152\u001B[0m     \u001B[0mstrategy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdistribute\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_strategy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\DataScience\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weights, steps, **kwargs)\u001B[0m\n\u001B[0;32m    706\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_user_steps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msteps\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    707\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 708\u001B[1;33m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_args\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weights\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msteps\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    709\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    710\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mget_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\DataScience\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m_validate_args\u001B[1;34m(self, y, sample_weights, steps)\u001B[0m\n\u001B[0;32m    739\u001B[0m     \u001B[1;31m# Arguments that shouldn't be passed.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    740\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_none_or_empty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 741\u001B[1;33m       raise ValueError(\"`y` argument is not supported when using \"\n\u001B[0m\u001B[0;32m    742\u001B[0m                        \"dataset as input.\")\n\u001B[0;32m    743\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_none_or_empty\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample_weights\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: `y` argument is not supported when using dataset as input."
     ]
    }
   ],
   "source": [
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(train_set, train_set,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_set,test_set))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoded_imgs = encoder.predict(test_set)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}